{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T14:15:43.506183Z",
     "start_time": "2025-05-20T14:14:50.013057Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18,ResNet18_Weights\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:15:52.466959Z",
     "start_time": "2025-05-20T14:15:52.459522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KucingAnjingDataset(Dataset):\n",
    "\n",
    "\tdef __init__(self, root_dir, random_seed=42, image_size=224):\n",
    "\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.image_size = image_size\n",
    "\n",
    "\t\tif not os.path.exists(self.root_dir):\n",
    "\t\t\traise RuntimeError(f\"Dataset not found at {self.root_dir}.\")\n",
    "\n",
    "\n",
    "\t\tself.transform = transforms.Compose([\n",
    "        \ttransforms.Resize((self.image_size, self.image_size)),\n",
    "        \ttransforms.ToTensor(),\n",
    "        \ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "\t\tself.data = []\n",
    "\t\tself.labels = []\n",
    "\n",
    "\t\tfor label, class_name in tqdm(enumerate(['cats','dogs'])):\n",
    "\t\t\tclass_dir = os.path.join(self.root_dir, class_name)\n",
    "\t\t\timage_paths = glob.glob(os.path.join(class_dir,'*.jpg'))\n",
    "\t\t\tself.data.extend(image_paths)\n",
    "\t\t\tself.labels.extend([label] * len(image_paths))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage_path = self.data[idx]\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\timage = Image.open(image_path).convert('RGB')\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)\n",
    "\n",
    "\t\treturn image, label"
   ],
   "id": "a1dba8d18e8f3310",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:27:53.765011Z",
     "start_time": "2025-05-20T14:27:43.915684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "train_dataset = KucingAnjingDataset(root_dir='dataset/Week04/train')\n",
    "test_dataset  = KucingAnjingDataset(root_dir='dataset/Week04/test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(train_dataset))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "b0b215cb1bf12b6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 399.97it/s]\n",
      "2it [00:00, 1000.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\mrcah/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:09<00:00, 5.16MB/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:28:14.657481Z",
     "start_time": "2025-05-20T14:28:14.647693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params / 1e6:.2f}M\")\n",
    "print(f\"Trainable parameters: {trainable_params / 1e6:.2f}M\")"
   ],
   "id": "8f1c30c0fdf36ee4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11.46M\n",
      "Trainable parameters: 11.46M\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:31:04.505671Z",
     "start_time": "2025-05-20T14:29:14.549881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epoch = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\tmodel.train()\n",
    "\n",
    "\ttrain_loss = 0\n",
    "\n",
    "\tfor data, labels in tqdm(train_loader):\n",
    "\n",
    "\t\tdata, labels = data.to(device), labels.to(device)\n",
    "\t\tbs = data.size()[0]\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\toutputs = model(data)\n",
    "\t\tloss = criterion(outputs, labels)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\ttrain_loss += loss.item() * data.size(0)\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\ttest_loss = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data, labels in tqdm(test_loader):\n",
    "\t\t\tdata, labels = data.to(device), labels.to(device)\n",
    "\t\t\tbs = data.size()[0]\n",
    "\t\t\toutputs = model(data)\n",
    "\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\ttest_loss += loss.item() * data.size(0)\n",
    "\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tcorrect += (preds == labels).sum().item()\n",
    "\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\n",
    "\tacc = correct / total\n",
    "\tavg_train_loss = train_loss / len(train_dataset)\n",
    "\tavg_test_loss = test_loss / len(test_dataset)\n",
    "\n",
    "\ttrain_losses.append(avg_train_loss)\n",
    "\ttest_losses.append(avg_test_loss)\n",
    "\n",
    "\tprint(f\"Epoch {epoch+1}: Train Loss {avg_train_loss:.4f}, Test Loss {avg_test_loss:.4f}, Test Acc {acc:.4f}\")\n"
   ],
   "id": "5dc0ad1e7861aaa3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.82it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 4.3022, Test Loss 1.6220, Test Acc 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.8870, Test Loss 0.9322, Test Acc 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.94it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.2064, Test Loss 0.7500, Test Acc 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.1133, Test Loss 0.3967, Test Acc 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.89it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0570, Test Loss 0.3473, Test Acc 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0246, Test Loss 0.3203, Test Acc 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0226, Test Loss 0.2926, Test Acc 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.07it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0213, Test Loss 0.2428, Test Acc 0.9643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0147, Test Loss 0.2534, Test Acc 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0145, Test Loss 0.2519, Test Acc 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:31:20.812891Z",
     "start_time": "2025-05-20T14:31:20.450736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save({\n",
    "    'epoch': num_epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_loss': train_losses,\n",
    "    'test_loss': test_losses,\n",
    "}, 'cat_dog_checkpoint.pth')"
   ],
   "id": "f0cde0bd276dae58",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
